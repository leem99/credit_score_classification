{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9726316",
   "metadata": {},
   "source": [
    "## Develop Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11565122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import distributions\n",
    "import mlflow \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8272e",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ae62388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogUniformInt:\n",
    "    \n",
    "    def __init__(self, min_val, max_val):\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val \n",
    "        \n",
    "    def rvs(self, random_state=None):\n",
    "        \"\"\"\n",
    "        rvs method that is needed by RandomSearchCV\n",
    "        \"\"\"\n",
    "        \n",
    "        # call the loguniform distribution that is built into scipy\n",
    "        lu = distributions.loguniform(self.min_val, self.max_val)\n",
    "        \n",
    "        # convert outut to integer\n",
    "        rand_int = int(lu.rvs(random_state=random_state))\n",
    "        \n",
    "        return rand_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb8b90c",
   "metadata": {},
   "source": [
    "Create our MLflow Database to Log Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272bcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53246e78",
   "metadata": {},
   "source": [
    "#### Read in and standardize data\n",
    "\n",
    "\n",
    "We will apply a standard scaler.\n",
    "This is just for computational efficiency (avoid any floating point error).\n",
    "\n",
    "Decision tree based methods are relatively scale invariant, and don't really need standardization.\n",
    "This makes intuitive sense; when splitting on a feature,\n",
    "we are just picking that value that minimizing entropy. As long as,\n",
    "rank order is preserved in the feature column, we should get the same result.\n",
    "\n",
    "Relevant [Stack Exchange post](https://stats.stackexchange.com/questions/255765/does-random-forest-need-input-variables-to-be-scaled-or-centered).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fec09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training data\n",
    "X_train_df = pd.read_csv(\"train_cleaned.csv\")\n",
    "y_train_df = X_train_df.pop(\"Credit_Score\")\n",
    "y_train = y_train_df.values\n",
    "\n",
    "# get dev data\n",
    "X_dev_df = pd.read_csv(\"dev_cleaned.csv\")\n",
    "y_dev_df = X_dev_df.pop(\"Credit_Score\")\n",
    "y_dev = y_dev_df.values\n",
    "\n",
    "# Standardize our data\n",
    "X_train = StandardScaler().fit_transform(X_train_df)\n",
    "X_dev = StandardScaler().fit_transform(X_dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a0babc",
   "metadata": {},
   "source": [
    "Train Model\n",
    "\n",
    "According to the `RandomSearchCV` [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html), our param_distributions are lists that will be sampled uniformly or distributions with a `rvs` method for sampling (such as those from scipy.stats.distributions).\n",
    "\n",
    "\n",
    "[Example project](https://jamesrledoux.com/code/randomized_parameter_search) using `RandomSearchCV`.\n",
    "\n",
    "For values that can span mulitiple orders of magnitude, \n",
    "we will want to sample using a [loguniform distribution](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.loguniform.html#scipy.stats.loguniform).\n",
    "[This blog post](https://towardsdatascience.com/why-is-the-log-uniform-distribution-useful-for-hyperparameter-tuning-63c8d331698) does a good job of explaining why to use the log normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators = 1000)\n",
    "\n",
    "# ----- Parameter Distributions -----\n",
    "param_dists = {\"max_depth\": distributions.randint(2, 20),\n",
    "               \"min_samples_split\": LogUniformInt(min_val=2, max_val=50),\n",
    "               \"max_leaf_nodes\": distributions.randint(2, 10),\n",
    "               # normally distributed max_features, with mean .25 stddev 0.1, bounded between 0 and 1\n",
    "               \"max_features\":  distributions.truncnorm(a=0, b=1, loc=0.25, scale=0.1)}\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(rfc_model,\n",
    "                         param_dists,\n",
    "                         n_iter=2,\n",
    "                         cv=5, # for classification defaults to StratefiedKFold\n",
    "                         random_state=99)\n",
    "\n",
    "\n",
    "cv_model = clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# get the best params\n",
    "best_params = cv_model.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c118cd",
   "metadata": {},
   "source": [
    "__Generate predictions__: on our dev set, so that we can compare to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c68c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rfc_model = RandomForestClassifier(**best_params)\n",
    "best_rfc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_rfc_model.predict(X_dev)\n",
    "score = f1_score(y_true=y_dev,\n",
    "                 y_pred=y_pred,\n",
    "                 average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a7b099",
   "metadata": {},
   "source": [
    "__Log Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f730ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
